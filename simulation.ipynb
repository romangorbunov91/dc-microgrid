{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626feeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0148e2",
   "metadata": {},
   "source": [
    "# Симулятор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8819da5",
   "metadata": {},
   "source": [
    "Импорт моделей энергосети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_models import PowerGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6c756",
   "metadata": {},
   "source": [
    "Импорт моделей агентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d6058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b09120dc",
   "metadata": {},
   "source": [
    "Импорт функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a61427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_func import reward_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e764e4a",
   "metadata": {},
   "source": [
    "## Диапазоны параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6f1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1991\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "# Bus.\n",
    "Ubus_nom = 48.0\n",
    "Ubus_init = 0.95*Ubus_nom\n",
    "beta_bus = 0.01e-3/(6*6*1800e-6) # dt/C\n",
    "\n",
    "# Sources.\n",
    "N_SOURCE = 5\n",
    "Usource_init_min, Usource_init_max = [0.10*Ubus_nom, 0.95*Ubus_nom]\n",
    "Rdroop_min, Rdroop_max = [2e-3, 20e-3]\n",
    "beta_source_min, beta_source_max = [0.8, 0.9]\n",
    "Uref_rnd_min, Uref_rnd_max = [0.95*Ubus_nom, 1.05*Ubus_nom]\n",
    "\n",
    "Usource_init_set = rng.uniform(Usource_init_min, Usource_init_max, size=N_SOURCE)\n",
    "Rdroop_set = rng.uniform(Rdroop_min, Rdroop_max, size=N_SOURCE)\n",
    "beta_source_set = rng.uniform(beta_source_min, beta_source_max, size=N_SOURCE)\n",
    "Uref_set = rng.uniform(Uref_rnd_min, Uref_rnd_max, size=N_SOURCE)\n",
    "\n",
    "# Loads.\n",
    "N_LOAD = 10\n",
    "Prnd_min, Prnd_max = [10.0, 8.5e3]\n",
    "beta_load_min, beta_load_max = [0.1, 0.9]\n",
    "\n",
    "beta_load_set = rng.uniform(beta_load_min, beta_load_max, size=N_LOAD)\n",
    "Uload_nom_set = np.full_like(beta_load_set, Ubus_nom)\n",
    "Iload_init_set = np.full_like(beta_load_set, 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958efd82",
   "metadata": {},
   "source": [
    "Конфигурация энергосети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9b798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "microgrid = PowerGrid(\n",
    "    N_SOURCE = N_SOURCE,\n",
    "    N_LOAD = N_LOAD,\n",
    "    Rdroop_set = Rdroop_set,\n",
    "    Ubus_init = Ubus_init,\n",
    "    Usource_init_set = Usource_init_set,\n",
    "    Uload_nom_set = Uload_nom_set,\n",
    "    Iload_init_set =Iload_init_set,\n",
    "    beta_bus = beta_bus,\n",
    "    beta_source_set = beta_source_set,\n",
    "    beta_load_set = beta_load_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015148e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 200\n",
    "N_TRAIN = 10\n",
    "seed_generator = rng.integers(0, 2**32, size=N_TRAIN, dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5ea94",
   "metadata": {},
   "source": [
    "Основной цикл симуляции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409b56de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мощность системы электроснабжения: 51328.25\n",
      "Напряжение на шине, В:, 45.70\n",
      "Токи источников, А: [300.75 391.23 129.33   7.22 189.52]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [300.75 189.52 391.23  49.5   48.75  49.28]\n",
      "Состояния агента 1: [391.23 300.75 129.33  49.28  49.5   46.88]\n",
      "Состояния агента 2: [129.33 391.23   7.22  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [  7.22 129.33 189.52  45.8   46.88  48.75]\n",
      "Состояния агента 4: [189.52   7.22 300.75  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [300.75 391.23 129.33   7.22 189.52  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 43114.89\n",
      "Напряжение на шине, В:, 46.06\n",
      "Токи источников, А: [272.   351.58  89.57 -18.19 166.99]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [272.   166.99 351.58  49.5   48.75  49.28]\n",
      "Состояния агента 1: [351.58 272.    89.57  49.28  49.5   46.88]\n",
      "Состояния агента 2: [ 89.57 351.58 -18.19  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-18.19  89.57 166.99  45.8   46.88  48.75]\n",
      "Состояния агента 4: [166.99 -18.19 272.    48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [272.   351.58  89.57 -18.19 166.99  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 34111.98\n",
      "Напряжение на шине, В:, 46.47\n",
      "Токи источников, А: [239.96 307.38  45.26 -46.52 141.87]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [239.96 141.87 307.38  49.5   48.75  49.28]\n",
      "Состояния агента 1: [307.38 239.96  45.26  49.28  49.5   46.88]\n",
      "Состояния агента 2: [ 45.26 307.38 -46.52  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-46.52  45.26 141.87  45.8   46.88  48.75]\n",
      "Состояния агента 4: [141.87 -46.52 239.96  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [239.96 307.38  45.26 -46.52 141.87  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 45213.62\n",
      "Напряжение на шине, В:, 45.97\n",
      "Токи источников, А: [279.39 361.77  99.79 -11.66 172.78]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [279.39 172.78 361.77  49.5   48.75  49.28]\n",
      "Состояния агента 1: [361.77 279.39  99.79  49.28  49.5   46.88]\n",
      "Состояния агента 2: [ 99.79 361.77 -11.66  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-11.66  99.79 172.78  45.8   46.88  48.75]\n",
      "Состояния агента 4: [172.78 -11.66 279.39  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [279.39 361.77  99.79 -11.66 172.78  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 49028.46\n",
      "Напряжение на шине, В:, 45.80\n",
      "Токи источников, А: [2.9275e+02 3.8019e+02 1.1826e+02 1.5000e-01 1.8325e+02]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [292.75 183.25 380.19  49.5   48.75  49.28]\n",
      "Состояния агента 1: [380.19 292.75 118.26  49.28  49.5   46.88]\n",
      "Состояния агента 2: [1.1826e+02 3.8019e+02 1.5000e-01 4.6880e+01 4.9280e+01 4.5800e+01]\n",
      "Состояния агента 3: [1.5000e-01 1.1826e+02 1.8325e+02 4.5800e+01 4.6880e+01 4.8750e+01]\n",
      "Состояния агента 4: [1.8325e+02 1.5000e-01 2.9275e+02 4.8750e+01 4.5800e+01 4.9500e+01]\n",
      "Состояние микрогрида: [2.9275e+02 3.8019e+02 1.1826e+02 1.5000e-01 1.8325e+02 4.9500e+01\n",
      " 4.9280e+01 4.6880e+01 4.5800e+01 4.8750e+01]\n",
      "Мощность системы электроснабжения: 28560.95\n",
      "Напряжение на шине, В:, 46.72\n",
      "Токи источников, А: [219.93 279.74  17.55 -64.23 126.17]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [219.93 126.17 279.74  49.5   48.75  49.28]\n",
      "Состояния агента 1: [279.74 219.93  17.55  49.28  49.5   46.88]\n",
      "Состояния агента 2: [ 17.55 279.74 -64.23  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-64.23  17.55 126.17  45.8   46.88  48.75]\n",
      "Состояния агента 4: [126.17 -64.23 219.93  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [219.93 279.74  17.55 -64.23 126.17  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 38993.43\n",
      "Напряжение на шине, В:, 46.25\n",
      "Токи источников, А: [257.41 331.44  69.38 -31.1  155.54]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [257.41 155.54 331.44  49.5   48.75  49.28]\n",
      "Состояния агента 1: [331.44 257.41  69.38  49.28  49.5   46.88]\n",
      "Состояния агента 2: [ 69.38 331.44 -31.1   46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-31.1   69.38 155.54  45.8   46.88  48.75]\n",
      "Состояния агента 4: [155.54 -31.1  257.41  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [257.41 331.44  69.38 -31.1  155.54  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 22199.17\n",
      "Напряжение на шине, В:, 47.01\n",
      "Токи источников, А: [196.69 247.69 -14.58 -84.77 107.95]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [196.69 107.95 247.69  49.5   48.75  49.28]\n",
      "Состояния агента 1: [247.69 196.69 -14.58  49.28  49.5   46.88]\n",
      "Состояния агента 2: [-14.58 247.69 -84.77  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-84.77 -14.58 107.95  45.8   46.88  48.75]\n",
      "Состояния агента 4: [107.95 -84.77 196.69  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [196.69 247.69 -14.58 -84.77 107.95  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 25503.42\n",
      "Напряжение на шине, В:, 46.86\n",
      "Токи источников, А: [208.79 264.39   2.16 -74.07 117.44]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [208.79 117.44 264.39  49.5   48.75  49.28]\n",
      "Состояния агента 1: [264.39 208.79   2.16  49.28  49.5   46.88]\n",
      "Состояния агента 2: [  2.16 264.39 -74.07  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-74.07   2.16 117.44  45.8   46.88  48.75]\n",
      "Состояния агента 4: [117.44 -74.07 208.79  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [208.79 264.39   2.16 -74.07 117.44  49.5   49.28  46.88  45.8   48.75]\n",
      "Мощность системы электроснабжения: 32159.20\n",
      "Напряжение на шине, В:, 46.55\n",
      "Токи источников, А: [232.94 297.69  35.55 -52.73 136.37]\n",
      "Напряжения источников, В: [49.5  49.28 46.88 45.8  48.75]\n",
      "Состояния агента 0: [232.94 136.37 297.69  49.5   48.75  49.28]\n",
      "Состояния агента 1: [297.69 232.94  35.55  49.28  49.5   46.88]\n",
      "Состояния агента 2: [ 35.55 297.69 -52.73  46.88  49.28  45.8 ]\n",
      "Состояния агента 3: [-52.73  35.55 136.37  45.8   46.88  48.75]\n",
      "Состояния агента 4: [136.37 -52.73 232.94  48.75  45.8   49.5 ]\n",
      "Состояние микрогрида: [232.94 297.69  35.55 -52.73 136.37  49.5   49.28  46.88  45.8   48.75]\n"
     ]
    }
   ],
   "source": [
    "bus_voltage = []\n",
    "for m in range(N_TRAIN):\n",
    "    load_random = np.random.default_rng(seed_generator[m])\n",
    "    \n",
    "    Pload_set = load_random.uniform(Prnd_min, Prnd_max, size=N_LOAD)\n",
    "    beta_load_set = load_random.uniform(beta_load_min, beta_load_max, size=N_LOAD)\n",
    "    trans_vals, steady_vals, agent_states, global_state = microgrid.step(\n",
    "        N_STEPS = N_STEPS,\n",
    "        Uref_set = Uref_set,\n",
    "        Pload_set = Pload_set)\n",
    "    \n",
    "    bus_voltage.extend(trans_vals[0])\n",
    "    \n",
    "    print(f'Мощность системы электроснабжения: {np.sum(Pload_set):.2f}')\n",
    "    print(f'Напряжение на шине, В:, {steady_vals[0]:.2f}')\n",
    "    print(f'Токи источников, А:', np.round(steady_vals[1],2))\n",
    "    print(f'Напряжения источников, В:', np.round(steady_vals[2],2))\n",
    "    for idx, agent in enumerate(agent_states):\n",
    "        print(f'Состояния агента {idx}:', np.round(agent, 2))\n",
    "    print(f'Состояние микрогрида:', np.round(global_state,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 2. Safe Action Mechanism (DEAA)\n",
    "# ===========================\n",
    "class SafeActionMechanism:\n",
    "    def __init__(self, eta=0.5, phi=0.2, U_ref=50.0):\n",
    "        self.eta = eta\n",
    "        self.phi = phi\n",
    "        self.L = U_ref\n",
    "        self.T = 0.0\n",
    "\n",
    "    def smooth(self, raw_action):\n",
    "        L_new = self.eta * raw_action + (1 - self.eta) * (self.L + self.T)\n",
    "        T_new = self.phi * (L_new - self.L) + (1 - self.phi) * self.T\n",
    "        safe = L_new + T_new\n",
    "        self.L, self.T = L_new, T_new\n",
    "        return safe\n",
    "\n",
    "# ===========================\n",
    "# 3. Reward Function (Algorithm 1)\n",
    "# ===========================\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# 4. State Normalizer\n",
    "# ===========================\n",
    "class RunningNormalizer:\n",
    "    def __init__(self, shape):\n",
    "        self.mean = np.zeros(shape, dtype=np.float32)\n",
    "        self.var = np.ones(shape, dtype=np.float32)\n",
    "        self.count = 1e-4\n",
    "\n",
    "    def update(self, x):\n",
    "        batch_mean = np.mean(x, axis=0)\n",
    "        batch_var = np.var(x, axis=0)\n",
    "        batch_count = x.shape[0]\n",
    "\n",
    "        delta = batch_mean - self.mean\n",
    "        tot_count = self.count + batch_count\n",
    "        self.mean += delta * batch_count / tot_count\n",
    "        m_a = self.var * self.count\n",
    "        m_b = batch_var * batch_count\n",
    "        M2 = m_a + m_b + np.square(delta) * self.count * batch_count / tot_count\n",
    "        self.var = M2 / tot_count\n",
    "        self.count = tot_count\n",
    "\n",
    "    def normalize(self, x):\n",
    "        return (x - self.mean) / (np.sqrt(self.var) + 1e-8)\n",
    "\n",
    "# ===========================\n",
    "# 5. SMAPPO Agent\n",
    "# ===========================\n",
    "class SMAPPO:\n",
    "    def __init__(self, obs_dim, action_dim, global_dim, lr_actor=1.5e-4, lr_critic=1e-4,\n",
    "                 clip_eps=0.2, ent_coef=0.01, gamma=0.8, gae_lambda=0.95):\n",
    "        self.actor = Actor(obs_dim, action_dim).to(device)\n",
    "        self.critic = Critic(global_dim).to(device)\n",
    "        self.actor_opt = optim.Adam(self.actor.parameters(), lr=lr_actor)\n",
    "        self.critic_opt = optim.Adam(self.critic.parameters(), lr=lr_critic)\n",
    "        self.clip_eps = clip_eps\n",
    "        self.ent_coef = ent_coef\n",
    "        self.gamma = gamma\n",
    "        self.gae_lambda = gae_lambda\n",
    "\n",
    "    def compute_gae(self, rewards, values, dones, next_value):\n",
    "        advantages = []\n",
    "        gae = 0\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            if i == len(rewards) - 1:\n",
    "                next_val = next_value\n",
    "            else:\n",
    "                next_val = values[i + 1]\n",
    "            delta = rewards[i] + self.gamma * next_val * (1 - dones[i]) - values[i]\n",
    "            gae = delta + self.gamma * self.gae_lambda * (1 - dones[i]) * gae\n",
    "            advantages.insert(0, gae)\n",
    "        advantages = torch.tensor(advantages, dtype=torch.float32, device=device)\n",
    "        returns = advantages + torch.tensor(values, dtype=torch.float32, device=device)\n",
    "        return advantages, returns\n",
    "\n",
    "    def update(self, data, epochs=10, batch_size=64):\n",
    "        obs = torch.tensor(data['obs'], dtype=torch.float32, device=device)\n",
    "        global_obs = torch.tensor(data['global_obs'], dtype=torch.float32, device=device)\n",
    "        actions = torch.tensor(data['actions'], dtype=torch.float32, device=device)\n",
    "        logprobs = torch.tensor(data['logprobs'], dtype=torch.float32, device=device)\n",
    "        returns = data['returns']\n",
    "        advantages = data['advantages']\n",
    "\n",
    "        n = len(obs)\n",
    "        indices = np.arange(n)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            np.random.shuffle(indices)\n",
    "            for start in range(0, n, batch_size):\n",
    "                idx = indices[start:start+batch_size]\n",
    "                obs_b = obs[idx]\n",
    "                global_obs_b = global_obs[idx]\n",
    "                actions_b = actions[idx]\n",
    "                logprobs_b = logprobs[idx]\n",
    "                returns_b = returns[idx]\n",
    "                advantages_b = advantages[idx]\n",
    "\n",
    "                # Normalize advantages\n",
    "                advantages_b = (advantages_b - advantages_b.mean()) / (advantages_b.std() + 1e-8)\n",
    "\n",
    "                # Critic loss\n",
    "                values_pred = self.critic(global_obs_b)\n",
    "                critic_loss = F.mse_loss(values_pred, returns_b)\n",
    "\n",
    "                self.critic_opt.zero_grad()\n",
    "                critic_loss.backward()\n",
    "                self.critic_opt.step()\n",
    "\n",
    "                # Actor loss\n",
    "                mean_new, log_std_new = self.actor(obs_b)\n",
    "                std_new = log_std_new.exp()\n",
    "                dist_new = Normal(mean_new, std_new)\n",
    "                logp_new = dist_new.log_prob(actions_b).sum(-1, keepdim=True)\n",
    "                logp_new -= (2 * (np.log(2) - torch.tanh(actions_b) - F.softplus(-2 * torch.tanh(actions_b)))).sum(-1, keepdim=True)\n",
    "\n",
    "                ratio = torch.exp(logp_new - logprobs_b)\n",
    "                surr1 = ratio * advantages_b\n",
    "                surr2 = torch.clamp(ratio, 1 - self.clip_eps, 1 + self.clip_eps) * advantages_b\n",
    "                actor_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                entropy = dist_new.entropy().sum(-1).mean()\n",
    "                actor_loss -= self.ent_coef * entropy\n",
    "\n",
    "                self.actor_opt.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                self.actor_opt.step()\n",
    "\n",
    "# ===========================\n",
    "# 6. Имитация среды (замените на реальную)\n",
    "# ===========================\n",
    "def mock_env_step(safe_actions, n_agents=4):\n",
    "    # Моделируем изменения напряжения и тока\n",
    "    base_U = 50.0\n",
    "    base_I = np.random.uniform(-10, 10, n_agents)\n",
    "    U = base_U + np.random.normal(0, 0.5, n_agents) + 0.01 * np.sum(safe_actions - base_U)\n",
    "    I = base_I + np.random.normal(0, 0.2, n_agents)\n",
    "\n",
    "    # Наблюдения: [I_self, I_neigh1, I_neigh2, U_self, U_neigh1, U_neigh2]\n",
    "    obs_list = []\n",
    "    for i in range(n_agents):\n",
    "        I_self = I[i]\n",
    "        U_self = U[i]\n",
    "        I_n = [I[(i-1)%n_agents], I[(i+1)%n_agents]]\n",
    "        U_n = [U[(i-1)%n_agents], U[(i+1)%n_agents]]\n",
    "        obs = np.array([I_self] + I_n + [U_self] + U_n, dtype=np.float32)\n",
    "        obs_list.append(obs)\n",
    "\n",
    "    global_obs = np.concatenate(obs_list, dtype=np.float32)\n",
    "    local_obs = np.stack(obs_list)\n",
    "    done = False\n",
    "    return local_obs, global_obs, U, I, done\n",
    "\n",
    "# ===========================\n",
    "# 7. Основной цикл обучения\n",
    "# ===========================\n",
    "if __name__ == \"__main__\":\n",
    "    n_agents = 4\n",
    "    obs_dim = 6\n",
    "    action_dim = 1\n",
    "    global_dim = n_agents * obs_dim\n",
    "    max_steps = 400\n",
    "    tau = 20\n",
    "    batch_size = 168\n",
    "\n",
    "    agent = SMAPPO(obs_dim, action_dim, global_dim, batch_size=batch_size)\n",
    "    safe_mechs = [SafeActionMechanism() for _ in range(n_agents)]\n",
    "    state_norm = RunningNormalizer(obs_dim)\n",
    "\n",
    "    num_episodes = 1000\n",
    "    for ep in range(num_episodes):\n",
    "        # Reset\n",
    "        local_obs, global_obs, _, _, _ = mock_env_step(np.full(n_agents, 50.0))\n",
    "        count = 0\n",
    "        buffer = {k: [] for k in ['obs', 'global_obs', 'actions', 'logprobs', 'rewards', 'dones', 'values']}\n",
    "\n",
    "        for t in range(max_steps):\n",
    "            # Нормализуем входы\n",
    "            local_obs_norm = np.array([state_norm.normalize(o) for o in local_obs])\n",
    "            actions_raw = []\n",
    "            logprobs_raw = []\n",
    "            safe_actions = []\n",
    "\n",
    "            for i in range(n_agents):\n",
    "                o = torch.tensor(local_obs_norm[i:i+1], device=device)\n",
    "                a, logp = agent.actor.get_action(o)\n",
    "                a_cpu = a.cpu().item()\n",
    "                a_v = a_cpu * 10 + 50  # [-1,1] → [40,60]\n",
    "                a_safe = safe_mechs[i].smooth(a_v)\n",
    "                actions_raw.append(a_cpu)\n",
    "                logprobs_raw.append(logp.item())\n",
    "                safe_actions.append(a_safe)\n",
    "\n",
    "            # Шаг среды\n",
    "            next_local, next_global, voltages, currents, done = mock_env_step(safe_actions)\n",
    "            reward, count = compute_reward(voltages, currents, count, tau)\n",
    "\n",
    "            # Сохраняем значения value для GAE\n",
    "            with torch.no_grad():\n",
    "                val = agent.critic(torch.tensor(global_obs, dtype=torch.float32, device=device)).item()\n",
    "\n",
    "            buffer['obs'].append(local_obs.copy())\n",
    "            buffer['global_obs'].append(global_obs.copy())\n",
    "            buffer['actions'].append(actions_raw)\n",
    "            buffer['logprobs'].append(logprobs_raw)\n",
    "            buffer['rewards'].append(reward)\n",
    "            buffer['dones'].append(done)\n",
    "            buffer['values'].append(val)\n",
    "\n",
    "            local_obs, global_obs = next_local, next_global\n",
    "\n",
    "            # Обновляем нормализатор\n",
    "            state_norm.update(local_obs)\n",
    "\n",
    "        # Последнее значение для GAE\n",
    "        with torch.no_grad():\n",
    "            last_val = agent.critic(torch.tensor(global_obs, dtype=torch.float32, device=device)).item()\n",
    "\n",
    "        # Вычисляем GAE и returns\n",
    "        advantages, returns = agent.compute_gae(\n",
    "            buffer['rewards'], buffer['values'], buffer['dones'], last_val\n",
    "        )\n",
    "\n",
    "        # Подготавливаем данные\n",
    "        train_data = {\n",
    "            'obs': np.array(buffer['obs']),\n",
    "            'global_obs': np.array(buffer['global_obs']),\n",
    "            'actions': np.array(buffer['actions']),\n",
    "            'logprobs': np.array(buffer['logprobs']),\n",
    "            'returns': returns,\n",
    "            'advantages': advantages\n",
    "        }\n",
    "\n",
    "        # Обновляем агента\n",
    "        agent.update(train_data, batch_size=batch_size)\n",
    "\n",
    "        if ep % 20 == 0:\n",
    "            avg_r = np.mean(buffer['rewards'])\n",
    "            print(f\"Episode {ep}, Avg Reward: {avg_r:.3f}\")\n",
    "\n",
    "    print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c849975",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
